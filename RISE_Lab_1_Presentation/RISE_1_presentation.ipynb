{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RISE one. Presentation Document, presented by group 7.\n",
    "\n",
    "### youtube link: https://www.youtube.com/watch?v=MhteN-1sYwg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 1.Ray\n",
    "  \n",
    "Currently, Ray is only available for Linux and MacOS\n",
    "  \n",
    "how to install Ray (MacOS): `pip install -U ray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(num_cpus=4,num_gpus=4,resources={'CustomResource1': 1, 'CustomResource2': 4},\n",
    "         include_webui=False, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "    1) ray functions cannot be called directly\n",
    "    2) use ray.get() to retrieve the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow(i):\n",
    "    time.sleep(1.0)\n",
    "    return i\n",
    "\n",
    "@ray.remote\n",
    "def fast(i):\n",
    "    time.sleep(1.0)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "results = [slow(i) for i in range(10)]\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "results = [fast.remote(i) for i in range(10)]\n",
    "results = ray.get(results)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def first(a):\n",
    "    time.sleep(2.0)\n",
    "    a += 1\n",
    "    return a\n",
    "\n",
    "@ray.remote\n",
    "def second(b):\n",
    "    time.sleep(2.0)\n",
    "    b += 1\n",
    "    return b\n",
    "\n",
    "@ray.remote\n",
    "def thrid(c):\n",
    "    time.sleep(2.0)\n",
    "    c += 1\n",
    "    return c\n",
    "\n",
    "@ray.remote\n",
    "def forth(d):\n",
    "    time.sleep(2.0)\n",
    "    d += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "\n",
    "a = first.remote(a)\n",
    "b = second.remote(a)\n",
    "c = thrid.remote(b)\n",
    "d = forth.remote(c)\n",
    "\n",
    "d = ray.get(d)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo(object):\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def increment(self):\n",
    "        time.sleep(0.5)\n",
    "        self.counter += 1\n",
    "        return self.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f1 = Foo()\n",
    "f2 = Foo()\n",
    "f3 = Foo()\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "f1.reset()\n",
    "f2.reset()\n",
    "f3.reset()\n",
    "\n",
    "results = []\n",
    "for _ in range(5):\n",
    "    results.append(f1.increment())\n",
    "    results.append(f2.increment())\n",
    "    results.append(f3.increment())\n",
    "    \n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(results)\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Fooboo(object):\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def increment(self):\n",
    "        time.sleep(0.5)\n",
    "        self.counter += 1\n",
    "        return self.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb1 = Fooboo.remote()\n",
    "fb2 = Fooboo.remote()\n",
    "fb3 = Fooboo.remote()\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "fb1.reset.remote()\n",
    "fb2.reset.remote()\n",
    "fb3.reset.remote()\n",
    "\n",
    "results = []\n",
    "for _ in range(5):\n",
    "    results.append(fb1.increment.remote())\n",
    "    results.append(fb2.increment.remote())\n",
    "    results.append(fb3.increment.remote())\n",
    "results = ray.get(results)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(results)\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def f():\n",
    "    time.sleep(np.random.uniform(0, 5))\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "result_ids = [f.remote() for _ in range(10)]\n",
    "\n",
    "results = []\n",
    "for i in range(len(result_ids)):\n",
    "    ready_ids,result_ids = ray.wait(result_ids,1,None)\n",
    "    result = ray.get(ready_ids[0])\n",
    "    results.append(result)\n",
    "    print('Processing result which finished after {} seconds.'\n",
    "          .format(result - start_time))\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.put()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net_weights = {'variable{}'.format(i): np.random.normal(size=1000000)\n",
    "                      for i in range(50)}\n",
    "\n",
    "@ray.remote\n",
    "def use_weights(weights, i):\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "para = ray.put(neural_net_weights)\n",
    "results_ids = ray.get([use_weights.remote(para, i) for i in range(20)])\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU API and User-defined Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in ray.get_gpu_ids()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def f_gpu():\n",
    "    time.sleep(1)\n",
    "    return ray.get_gpu_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "start_time = time.time()\n",
    "\n",
    "runs = [f_gpu.remote() for _ in range(8)]\n",
    "runs = ray.get(runs)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(resources={'CustomResource2':2})\n",
    "def f_custom():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "start_time = time.time()\n",
    "\n",
    "runs = [f_custom.remote() for _ in range(5)]\n",
    "runs = ray.get(runs)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas vs modin.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import modin.pandas as mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_pd = pd.read_csv('log20161201.csv',low_memory=False)\n",
    "top = csv_pd.head()\n",
    "\n",
    "# CPU times: user 1min 55s, sys: 4min 8s, total: 6min 4s\n",
    "# Wall time: 10min 41s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_mpd = mpd.read_csv('log20161201.csv',low_memory=False)\n",
    "top = csv_mpd.head()\n",
    "\n",
    "# CPU times: user 152 ms, sys: 316 ms, total: 468 ms\n",
    "# Wall time: 5min 48s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 2. RLlib Exercise  - Proximal Policy Optimization\n",
    "\n",
    "**GOAL:** The goal of this exercise is to demonstrate how to use the proximal policy optimization (PPO) algorithm.\n",
    "\n",
    "To understand how to use **RLlib**, see the documentation at http://rllib.io.\n",
    "\n",
    "PPO is described in detail in https://arxiv.org/abs/1707.06347. It is a variant of Trust Region Policy Optimization (TRPO) described in https://arxiv.org/abs/1502.05477\n",
    "\n",
    "PPO works in two phases. In one phase, a large number of rollouts are performed (in parallel). The rollouts are then aggregated on the driver and a surrogate optimization objective is defined based on those rollouts. We then use SGD to find the policy that maximizes that objective with a penalty term for diverging too much from the current policy.\n",
    "\n",
    "![ppo](https://raw.githubusercontent.com/ucbrise/risecamp/risecamp2018/ray/tutorial/rllib_exercises/ppo.png)\n",
    "\n",
    "**NOTE:** The SGD optimization step is best performed in a data-parallel manner over multiple GPUs. This is exposed through the `num_gpus` field of the `config` dictionary (for this to work, you must be using a machine that has GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOAgent, DEFAULT_CONFIG\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up Ray. This must be done before we instantiate any RL agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a PPOAgent object. We pass in a config object that specifies how the network and training procedure should be configured. Some of the parameters are the following.\n",
    "\n",
    "- `num_workers` is the number of actors that the agent will create. This determines the degree of parallelism that will be used.\n",
    "- `num_sgd_iter` is the number of epochs of SGD (passes through the data) that will be used to optimize the PPO surrogate objective at each iteration of PPO.\n",
    "- `sgd_minibatch_size` is the SGD batch size that will be used to optimize the PPO surrogate objective.\n",
    "- `model` contains a dictionary of parameters describing the neural net used to parameterize the policy. The `fcnet_hiddens` parameter is a list of the sizes of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0  # This avoids running out of resources in the notebook environment when this cell is re-executed\n",
    "\n",
    "agent = PPOAgent(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the policy on the `CartPole-v0` environment for 2 steps. The CartPole problem is described at https://gym.openai.com/envs/CartPole-v0.\n",
    "\n",
    "**EXERCISE:** Inspect how well the policy is doing by looking for the lines that say something like\n",
    "\n",
    "```\n",
    "total reward is  22.3215974777\n",
    "trajectory length mean is  21.3215974777\n",
    "```\n",
    "\n",
    "This indicates how much reward the policy is receiving and how many time steps of the environment the policy ran. The maximum possible reward for this problem is 200. The reward and trajectory length are very close because the agent receives a reward of one for every time step that it survives (however, that is specific to this environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** The current network and training configuration are too large and heavy-duty for a simple problem like CartPole. Modify the configuration to use a smaller network and to speed up the optimization of the surrogate objective (fewer SGD iterations and a larger batch size should help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DEFAULT_CONFIG.copy()\n",
    "config['num_workers'] = 3\n",
    "config['num_sgd_iter'] = 30\n",
    "config['sgd_minibatch_size'] = 128\n",
    "config['model']['fcnet_hiddens'] = [100, 100]\n",
    "config['num_cpus_per_worker'] = 0\n",
    "\n",
    "agent = PPOAgent(config, 'CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Train the agent and try to get a reward of 200. If it's training too slowly you may need to modify the config above to use fewer hidden units, a larger `sgd_minibatch_size`, a smaller `num_sgd_iter`, or a larger `num_workers`.\n",
    "\n",
    "This should take around 20 or 30 training iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    result = agent.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint the current model. The call to `agent.save()` returns the path to the checkpointed model and can be used later to restore the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = agent.save()\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the trained policy to make predictions.\n",
    "\n",
    "**NOTE:** Here we are loading the trained policy in the same process, but in practice, this would often be done in a different process (probably on a different machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_config = config.copy()\n",
    "\n",
    "test_agent = PPOAgent(trained_config, 'CartPole-v0')\n",
    "test_agent.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the trained policy to act in an environment. The key line is the call to `test_agent.compute_action(state)` which uses the trained policy to choose an action.\n",
    "\n",
    "**EXERCISE:** Verify that the reward received roughly matches up with the reward printed in the training logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = test_agent.compute_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 3. Tune\n",
    "\n",
    "Tune is a scalable framework for model training and hyperparameter search with a focus on deep learning and deep reinforcement learning.\n",
    "\n",
    "**Code**: https://github.com/ray-project/ray/tree/master/python/ray/tune\n",
    "\n",
    "**Examples**: https://github.com/ray-project/ray/tree/master/python/ray/tune/examples\n",
    "\n",
    "**Documentation**: http://ray.readthedocs.io/en/latest/tune.html\n",
    "\n",
    "**Mailing List** https://groups.google.com/forum/#!forum/ray-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Tuning hyperparameters is often the most expensive part of the machine learning workflow. Tune is built to address this, demonstrating an efficient and scalable solution for this pain point.\n",
    "\n",
    "\n",
    "## Before getting started!\n",
    "\n",
    "Be sure to use Jupyter Notebook instead of Jupyter Lab for this tutorial! The URL should look something like:\n",
    "\n",
    "    http:/[[current hostname]]/camp/ray/jupyter/notebooks/tune_exercises/Tune.ipynb\n",
    "\n",
    "## Outline\n",
    "This tutorial will walk you through the following process:\n",
    "\n",
    "1. Creating and training a model on a toy dataset (MNIST)\n",
    "2. Integrating Tune into your workflow\n",
    "3. Trying out advanced features - plugging in an efficient scheduler\n",
    "4. Validating your trained model\n",
    "5. (Optional) Try out a search algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "limit_threads(4)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Creating a model to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Convolutional Neural Network model. Convolutional Neural Networks (ConvNets or CNNs) are a category of Neural Networks that have proven very effective in areas such as image recognition and classification. The details of how a Convolutional Neural Network works are unimportant here, but you're welcome to read more about them here: http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "<img src=\"cnn.png\" alt=\"MNIST Visualization\" width=\"800\"/>\n",
    "\n",
    "\n",
    "This convolutional neural network model will be used classify digits (from the MNIST dataset).\n",
    "\n",
    "<img src=\"mnist.png\" alt=\"MNIST Visualization\" width=\"400\"/>\n",
    "\n",
    "This is a fairly simple dataset, but it enables us to explore Tune's functionality in depth.\n",
    "We will use 60,000 images to train the network. The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the digit the image represents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll specify some arguments and some reasonable defaults for this model. These are the hyperparameters settings that we will later use to further optimize this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Keras MNIST Example')\n",
    "parser.add_argument('--lr', type=float, default=0.1, help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.0, help='SGD momentum')\n",
    "parser.add_argument('--kernel1', type=int, default=3, help='Size of first kernel')\n",
    "parser.add_argument('--kernel2', type=int, default=3, help='Size of second kernel')\n",
    "parser.add_argument('--poolsize', type=int, default=2, help='Size of Poolin')\n",
    "parser.add_argument('--dropout1', type=float, default=0.25, help='Size of first kernel')\n",
    "parser.add_argument('--hidden', type=int, default=4, help='Size of Hidden Layer')\n",
    "parser.add_argument('--dropout2', type=float, default=0.5, help='Size of first kernel')\n",
    "\n",
    "DEFAULT_ARGS = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This below function will create and return a Convolutional Neural Network. You don't need to modify this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(parameters):\n",
    "    config = DEFAULT_ARGS.copy()  # This is obtained via the global scope\n",
    "    config.update(parameters)\n",
    "    num_classes = 10\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(config[\"kernel1\"], config[\"kernel1\"]),\n",
    "                     activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(64, (config[\"kernel2\"], config[\"kernel2\"]), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(config[\"poolsize\"], config[\"poolsize\"])))\n",
    "    model.add(Dropout(config[\"dropout1\"]))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(config[\"hidden\"], activation='relu'))\n",
    "    model.add(Dropout(config[\"dropout2\"]))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(\n",
    "                      lr=config[\"lr\"], momentum=config[\"momentum\"]),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Setup a basic model training script.\n",
    "\n",
    "The process of training the neural network model occurs as follows:\n",
    "\n",
    "1. Feed the training data to the model—in this example, the `batch_of_data` and `batch_of_labels` arrays.\n",
    "2. The model learns to associate images and labels.\n",
    "\n",
    "**Exercise**: Fill out the TODO in the code below. Here are a few hints:\n",
    "\n",
    "1) `data_generator` is an iterator that returns (`batch_of_data`, `batch_of_labels`), like follows:\n",
    "\n",
    "```python\n",
    "for batch_of_data, batch_of_labels in data_generator:\n",
    "    do_something_interesting()\n",
    "```\n",
    "2) You can use `model.fit(batch_of_data, batch_of_labels)` to repeatedly improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(args):\n",
    "    \"\"\"Loads data, does one pass over the data, and saves the weights.\"\"\"\n",
    "    data_generator = load_data()\n",
    "    model = make_model(args)\n",
    "    for batch_of_data, batch_of_labels in data_generator:\n",
    "        model.fit(batch_of_data, batch_of_labels)\n",
    "    model.save_weights(\"./weights.h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this above training script to make sure things work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "first_model = train_mnist(DEFAULT_ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(first_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now quickly try out this model to see if it works as expected. We'll load the model with our trained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Try to write a digit into the box below. This will automatically save your input in a variable `data` behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = 78\n",
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tip: don't expect it to work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = prepare_data(data)\n",
    "print(\"This model predicted your input as\", first_model.predict(prepared_data).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You've now set up a model that we can use Tune to optimize!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Setting up Tune\n",
    "\n",
    "One thing we might want to do now is find better hyperparameters so that our model trains more quickly and possibly to a higher accuracy. Let's make some minor modifications to utilize Tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune uses Ray as a backend, so we will first import and initialize Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune will automate and distribute your hyperparameter search by scheduling a number of **trials** on a machine. Each trial runs a user-defined Python function with a sampled set of hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Two steps to use Tune:\n",
    "\n",
    "Step 1) For the function you wish to tune, we need to change the signature to a specific format as shown below. Specifically: **pass in a ``reporter`` object to the below `train_mnist_tune` class**.\n",
    "\n",
    "```python\n",
    "def trainable(config, reporter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        config (dict): Parameters provided from the search algorithm\n",
    "            or variant generation.\n",
    "        reporter (Reporter): Handle to report intermediate metrics to Tune.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "Step 2) We want to keep track of performance as the model is training. Specifically: **get the `mean_accuracy` from Keras, and call the ``reporter`` to report the `mean_accuracy` for every batch**. \n",
    "\n",
    "You can get model accuracy from Keras with the following code:\n",
    "\n",
    "```python\n",
    "mean_accuracy = model.evaluate(x_batch, y_batch)[1]\n",
    "```\n",
    "\n",
    "\n",
    "Example of using the reporter:\n",
    "\n",
    "```python\n",
    "def train_func(config, reporter):  # add a reporter arg\n",
    "    # ...\n",
    "    for data, target in dataset:\n",
    "        model.fit(data, target)\n",
    "        save_model()\n",
    "        accuracy = model.evaluate(x_batch, y_batch)[1]\n",
    "        reporter(mean_accuracy=accuracy, metric2=1, metric3=0.3, ...) # report metrics\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_tune(config): ### TODO: Change this function signature following step 1 #####\n",
    "    data_generator = load_data()\n",
    "    model = make_model(config)\n",
    "    for i, (x_batch, y_batch) in enumerate(data_generator):\n",
    "        model.fit(x_batch, y_batch, verbose=0)\n",
    "        if i % 3 == 0:\n",
    "            last_checkpoint = \"weights_tune_{}.h5\".format(i)\n",
    "            model.save_weights(last_checkpoint)\n",
    "        ### Don't change above ############### \n",
    "        \n",
    "        ### TODO: Use the reporter here to fill out intermediate metrics following step 2###\n",
    "        reporter(mean_accuracy=None, ## Change me\n",
    "                 timesteps_total=i, \n",
    "                 checkpoint=last_checkpoint)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take 30 seconds or so to run if incorrectly written\n",
    "assert test_reporter(train_mnist_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you've done this correctly, you now have properly converted your function to be Tune-compatible!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Let's now try to search over some parameters. \n",
    "\n",
    "*NOTE: You can find the documentation for this section here: https://ray.readthedocs.io/en/latest/tune-usage.html#specifying-experiments*\n",
    "\n",
    "In this section, we'll use some basic Tune features for training - namely specifying a stopping criteria and a search space. \n",
    "\n",
    "Let's first create a Tune Experiment specification. The relevant documentation for the Experiment class is here:\n",
    "\n",
    "```python\n",
    "class ray.tune.Experiment(name, run, stop=None, config=None, ... ):\n",
    "    \"\"\"Tracks experiment specifications.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): Name of experiment.\n",
    "        run (function|class|str): The algorithm or model to train.\n",
    "            This may refer to the name of a built-on algorithm\n",
    "            (e.g. RLLib's DQN or PPO), a user-defined trainable\n",
    "            function or class, or the string identifier of a\n",
    "            trainable function or class registered in the tune registry.\n",
    "        stop (dict): The stopping criteria. The keys may be any field in\n",
    "            the return result of 'train()', whichever is reached first.\n",
    "            Defaults to empty dict.\n",
    "        config (dict): Algorithm-specific configuration for Tune variant\n",
    "            generation (e.g. env, hyperparams). Defaults to empty dict.\n",
    "            Custom search algorithms may ignore this.\n",
    "        trial_resources (dict): Machine resources to allocate per trial,\n",
    "            e.g. ``{\"cpu\": 64, \"gpu\": 8}``. Note that GPUs will not be\n",
    "            assigned unless you specify them here. Defaults to 1 CPU and 0\n",
    "            GPUs in ``Trainable.default_resource_request()``.\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1**: First, **set the stopping criteria to when `mean_accuracy` passes `0.95`**. For example, to specify that trials will be stopped whenever they report `arbitrary_metric` that is `>= 500`, do:\n",
    "\n",
    "```python\n",
    "stop={\"arbitrary_metric\": 500}\n",
    "```\n",
    "\n",
    "\n",
    "**Part 2**: We also want to designate a search space. We'll search over *learning rate*, which sets the step size of our model update, and *momentum*, which helps accelerate gradients vectors in the right directions, thus leading to faster converging.\n",
    "\n",
    "You can use `tune.grid_search` to specify an axis of a grid search. By default, Tune also supports sampling parameters from user-specified lambda functions, which can be used independently or in combination with grid search.  The following example shows grid search over a set of values combined with random sampling from a lambda functions, generating 3 different trials. \n",
    "\n",
    "```python\n",
    "configuration = tune.Experiment(\n",
    "    # ...\n",
    "    config={\n",
    "        \"arbitrary_parameter1\": lambda spec: np.random.uniform(0.1, 100),\n",
    "        \"arbitrary_parameter2\": tune.grid_search([16, 64, 256]),\n",
    "        # ...\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "Specifically, \n",
    "1. randomly search for learning rate `\"lr\"` between 0.001 to 0.1,\n",
    "2. do a grid search over `\"momentum\"` for `[0.2, 0.4, 0.6]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = tune.Experiment(\n",
    "    \"experiment_name\",\n",
    "    run=train_mnist_tune,\n",
    "    trial_resources={\"cpu\": 4},\n",
    "    stop={},  # TODO: Part 1\n",
    "    config={}  # TODO: Part 2\n",
    ")\n",
    "\n",
    "assert configuration.spec.get(\"stop\", {}).get(\"mean_accuracy\") == 0.95\n",
    "assert \"grid_search\" in configuration.spec.get(\"config\", {}).get(\"momentum\", {})\n",
    "assert \"lr\" in configuration.spec.get(\"config\", {})\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run our experiment with a single line of code. \n",
    "\n",
    "*Note*: Be sure pay attention to the `acc` metric next to each running trial. That indicates the most recently reported mean accuracy for that trial. This should evaluate in less than a minute. The output will look something similar to:\n",
    "\n",
    "```\n",
    "== Status ==\n",
    "Using FIFO scheduling algorithm.\n",
    "Resources requested: 8/8 CPUs, 0/1 GPUs\n",
    "Result logdir: .../ray_results/experiment_name\n",
    "RUNNING trials:\n",
    " - train_mnist_tune_0_lr=0.085836,momentum=0.2:\tRUNNING [pid=44320], 4 s, 3 iter, 0.406 acc\n",
    " - train_mnist_tune_1_lr=0.062562,momentum=0.4:\tRUNNING [pid=44321], 3 s, 2 iter, 0.219 acc\n",
    " - train_mnist_tune_2_lr=0.099461,momentum=0.6:\tRUNNING [pid=44317], 3 s, 2 iter, 0.281 acc\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trials = tune.run_experiments(configuration, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can expect the result below to be about `0.6`, although your mileage may vary (and it's OK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best result is\", get_best_result(trials, metric=\"mean_accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You've run your first Tune experiment!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 4. Clipper\n",
    "First, we start Clipper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, xgboost as xgb, numpy as np\n",
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "cl = ClipperConnection(DockerContainerManager())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClipperConnection.start_clipper(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register our application.\n",
    "register_application(name, input_type, default_output, slo_micros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.register_application('xgboost-test', 'integers', 'default_pred', 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_point():\n",
    "    return [np.random.randint(255) for _ in range(784)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an XGBoost model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training matrix.\n",
    "dtrain = xgb.DMatrix(get_test_point(), label=[0])\n",
    "# We then create parameters, watchlist, and specify the number of rounds\n",
    "# This is code that we use to build our XGBoost Model, and your code may differ.\n",
    "param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "watchlist = [(dtrain, 'train')]\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round, watchlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our predict function for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xs):\n",
    "    return bst.predict(xgb.DMatrix(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, as well as a predict function, we must deploy our model container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clipper_admin.deployers import python as python_deployer\n",
    "# We specify which packages to install in the pkgs_to_install arg.\n",
    "# For example, if we wanted to install xgboost and psycopg2, we would use\n",
    "# pkgs_to_install = ['xgboost', 'psycopg2']\n",
    "python_deployer.deploy_python_closure(cl, name='xgboost-model', version=1,\n",
    "     input_type=\"integers\", func=predict, pkgs_to_install=['xgboost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to link the model container to our app, \n",
    "so that Clipper can route requests for the “xgboost-test” application to the “xgboost-model” container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.link_model_to_app('xgboost-test', 'xgboost-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "# Get Address\n",
    "addr = cl.get_query_addr()\n",
    "# Post Query\n",
    "response = requests.post(\n",
    "     \"http://%s/%s/predict\" % (addr, 'xgboost-test'),\n",
    "     headers={\"Content-type\": \"application/json\"},\n",
    "     data=json.dumps({\n",
    "         'input': get_test_point()\n",
    "     }))\n",
    "result = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == requests.codes.ok and result[\"default\"]:\n",
    "    print('A default prediction was returned.')\n",
    "elif response.status_code != requests.codes.ok:\n",
    "    print(result)\n",
    "    raise BenchmarkException(response.text)\n",
    "else:\n",
    "    print('Prediction Returned:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.stop_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
