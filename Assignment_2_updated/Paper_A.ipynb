{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data driven prediction models of energy use of appliances in a low-energy house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper presents and discusses data-driven predictive models for the energy use of appliances, because appliances represent a significant portion (between 20 and 30%) of the electrical energy demand. \n",
    "Through many former studies, we learn there are many features can make influences to appliances' power consumption, such as weather, location (ZIP code), age of building, ownership, presence of double pane windows, energy efficient light fixtures, floor area, pet ownership, number of refrigerators and entertainment devices, number of occupants and income level. Our task is to pick the most important factors in all these features, then use these features' data we already collected to predict the future consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA(Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can get an outline from a graph of appliances energy consumption for the whole period.  \n",
    "![image.png](./A_energyConsumption.png)  \n",
    "Then we can get a further knowledge from a distribution plot and a boxplot of all energy consumption.  \n",
    "![image.png](./A_distributionBoxplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we can learn the correlation between all the variables with the energy consumption of appliances by a pairs plot.  \n",
    "These Figures show the bivariate scatter plots below the diagonal, histogram plots along the diagonal and the Pearson correlation above it, which is a measure of the linear dependence between two variables. A correlation of 1 is total positive correlation, −1 is total negative correlation and 0 represents no correlation. In red the linear regression fits are shown for each pair.   \n",
    "![image.png](./A_PairsPlot.png)  \n",
    "Then an hourly heat map was created for four consecutive weeks of data to identify any time trends.  \n",
    "![image.png](./A_heatmap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset contains several features or parameters and considering that the airport weather station is not at the same location as the house, it is desirable to find out which parameters are the most important and which ones do not improve the prediction of the appliances’ energy consumption.  \n",
    "We use Boruta package and Classification and Regression Training package(CARET) here to finish this part of work.  \n",
    "Boruta is used to select all the relevant variables. It can also rank the variables in order of importance starting with the NSM variable.    \n",
    "![image.png](./A_Boruta.png)\n",
    "CARET tells us about the performance of the selected variables with respect to the RMSE. It includes the recursive feature elimination (RFE) to select the optimal inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the predictors can be considered relevant to minimize the RMSE, they all will be used to test four regression models (Linear Regression, Support Vector Machines-Radial(SVM), Random Forest and Gradient Boosting Machines(GBM))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression:  \n",
    "The first model trained was the multiple linear regression. The multiple linear regression uses all the available predictors and finds the appropriate slope quantifying the effect of each predictor and the response. However, by the residual plot from the the linear regression model(the residuals were computed as the difference between the real values and the predicted values), the relationship between the variables and the energy consumption of appliances is not well represented by the linear model since the residuals are not normally distributed around the horizontal axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines-Radial(SVM):  \n",
    "The support vector machine can use different kernels, and the radial basis function kernel has some numerical advantages. A SVM with radial kernel, SVM-radial, is employed in the present research. The SVM-radial model requires two tuning parameters, sigma and cost variables, besides the predictors. The optimal values for sigma (0.4) and the cost (12) variables were obtained with a grid search.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:  \n",
    "The random forest model is a Tree-based model. The random forest model is based on the output of several regression trees. However, each tree is built with a random sample of selected predictors. The idea behind this is to decorrelate the trees and improve the prediction. The random forest model requires finding the optimum number of trees and the number of randomly selected predictors. The RMSE does not appear to change after about 300 trees and the optimal number of random selected predictors is 18 as seen in Appendix E. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Gradient Boosting Machines(GBM):  \n",
    "The GBM models (also known as boosting) try to improve the prediction by using information from the first trees and also require the selection of optimal parameters for the number of trees (10,900) and maximum tree depth (5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare the performance of each of the regression models, different performance evaluation indices are used here: the root mean squared error (RMSE), the coefficient of determination or R-squared/R2, the mean absolute error (MAE) and the mean absolute percentage error (MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best models are the ones that provide the lower RMSE and highest R2 values.  \n",
    "RF and GBM models have very similar and the best performance after we calculate these 4 evaluation values.   \n",
    "![image.png](./A_evaluationBefore.png)\n",
    "After finding out that the GBM model provided the best RMSE and R2 in the previous analysis, this model was used to study the prediction performance with different predictors subsets: removing the light consumption, removing the light and no weather data, removing the temperature and humidity from the wireless sensor network and only using the weather and time information.   \n",
    "![image.png](./A_evaluationAfter.png)  \n",
    "We can also have a look at all features' importance.  \n",
    "![image.png](./A_featuresImportance.png)\n",
    "Finally, we find the performance of the GBM model without the lights predictor is quite accurate in comparison with the GBM model. It also ranked the pressure as the most important weather variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
